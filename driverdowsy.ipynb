{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ec05e01-8559-4b49-a48a-e61ef7ff8212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting video capture. Press 'q' to quit.\n",
      "Drowsy Detection - Precision: 1.00, Recall: 0.58, F1 Score: 0.73\n",
      "Yawning Detection - Precision: 1.00, Recall: 0.74, F1 Score: 0.85\n"
     ]
    }
   ],
   "source": [
    "#live detection using video capture\n",
    "\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "def add_transparent_overlay(image, text_lines, start_x, start_y, padding=10):\n",
    "    \"\"\"Add semi-transparent background for text with overlay\"\"\"\n",
    "    overlay = image.copy()\n",
    "    max_width = 0\n",
    "    total_height = 0\n",
    "    line_heights = []\n",
    "    \n",
    "    for text, font_scale, _, thickness in text_lines:\n",
    "        (text_width, text_height), _ = cv2.getTextSize(\n",
    "            text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness\n",
    "        )\n",
    "        max_width = max(max_width, text_width)\n",
    "        line_heights.append(text_height + 10)\n",
    "        total_height += text_height + 10\n",
    "    \n",
    "    rect_x1 = start_x - padding\n",
    "    rect_y1 = start_y - padding\n",
    "    rect_x2 = start_x + max_width + padding\n",
    "    rect_y2 = start_y + total_height + padding\n",
    "    \n",
    "    alpha = 0.5\n",
    "    cv2.rectangle(overlay, (rect_x1, rect_y1), (rect_x2, rect_y2), (0, 0, 0), -1)\n",
    "    cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0, image)\n",
    "    \n",
    "    current_y = start_y\n",
    "    for (text, font_scale, color, thickness), line_height in zip(text_lines, line_heights):\n",
    "        cv2.putText(\n",
    "            image, text, (start_x, current_y + line_height - 5),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, thickness\n",
    "        )\n",
    "        current_y += line_height\n",
    "\n",
    "def calculate_EAR(eye):\n",
    "    \"\"\"Calculate Eye Aspect Ratio\"\"\"\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    EAR = (A + B) / (2.0 * C)\n",
    "    return EAR\n",
    "\n",
    "def calculate_MAR(mouth):\n",
    "    \"\"\"Calculate Mouth Aspect Ratio (MAR) for better yawn detection\"\"\"\n",
    "    V1 = dist.euclidean(mouth[3], mouth[9])    \n",
    "    V2 = dist.euclidean(mouth[2], mouth[10])   \n",
    "    V3 = dist.euclidean(mouth[1], mouth[11])   \n",
    "    H = dist.euclidean(mouth[0], mouth[6])     \n",
    "    MAR = (V1 + V2 + V3) / (3.0 * H)\n",
    "    return MAR\n",
    "\n",
    "def get_mouth_height_width_ratio(mouth):\n",
    "    \"\"\"Calculate the ratio of mouth height to width\"\"\"\n",
    "    mouth_top = min(point[1] for point in mouth[2:5])\n",
    "    mouth_bottom = max(point[1] for point in mouth[8:11])\n",
    "    mouth_left = min(point[0] for point in mouth[0:2])\n",
    "    mouth_right = max(point[0] for point in mouth[6:8])\n",
    "    height = dist.euclidean([0, mouth_top], [0, mouth_bottom])\n",
    "    width = dist.euclidean([mouth_left, 0], [mouth_right, 0])\n",
    "    return height / width if width > 0 else 0\n",
    "\n",
    "def preprocess_image(frame):\n",
    "    \"\"\"Enhanced preprocessing pipeline that maintains face detection reliability\"\"\"\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    gray = cv2.fastNlMeansDenoising(gray, None, 10, 7, 21)\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "    gray = cv2.filter2D(gray, -1, kernel)\n",
    "    gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    gray = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    return gray\n",
    "\n",
    "def detect_face_at_scales(detector, frame):\n",
    "    \"\"\"Attempt face detection at different scales\"\"\"\n",
    "    original_height, original_width = frame.shape[:2]\n",
    "    scales = [1.0, 2.0, 0.5]\n",
    "    \n",
    "    for scale in scales:\n",
    "        new_width, new_height = int(original_width * scale), int(original_height * scale)\n",
    "        resized_frame = cv2.resize(frame, (new_width, new_height))\n",
    "        rects = detector(resized_frame, 0)\n",
    "        \n",
    "        if len(rects) > 0:\n",
    "            scaled_rects = dlib.rectangles()\n",
    "            for rect in rects:\n",
    "                scaled_rect = dlib.rectangle(\n",
    "                    int(rect.left() / scale), int(rect.top() / scale),\n",
    "                    int(rect.right() / scale), int(rect.bottom() / scale)\n",
    "                )\n",
    "                scaled_rects.append(scaled_rect)\n",
    "            return scaled_rects\n",
    "    return dlib.rectangles()\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        detector = dlib.get_frontal_face_detector()\n",
    "        predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error loading facial landmark detector: {e}\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video capture device\")\n",
    "        return\n",
    "\n",
    "    print(\"Starting video capture. Press 'q' to quit.\")\n",
    "\n",
    "    drowsy_frames = 0\n",
    "    yawn_frames = 0\n",
    "    DROWSY_THRESHOLD = 10\n",
    "    YAWN_THRESHOLD = 5  \n",
    "    MAR_THRESHOLD = 0.6  \n",
    "    HEIGHT_WIDTH_RATIO_THRESHOLD = 0.5  \n",
    "\n",
    "    total_frames = 0\n",
    "    true_positive_drowsy = false_positive_drowsy = true_negative_drowsy = false_negative_drowsy = 0\n",
    "    true_positive_yawn = false_positive_yawn = true_negative_yawn = false_negative_yawn = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Could not read frame\")\n",
    "            break\n",
    "\n",
    "        total_frames += 1\n",
    "        processed_frame = preprocess_image(frame)\n",
    "        faces = detect_face_at_scales(detector, processed_frame)\n",
    "\n",
    "        for rect in faces:\n",
    "            shape = predictor(processed_frame, rect)\n",
    "            left_eye = np.array([(shape.part(i).x, shape.part(i).y) for i in range(36, 42)])\n",
    "            right_eye = np.array([(shape.part(i).x, shape.part(i).y) for i in range(42, 48)])\n",
    "            mouth = np.array([(shape.part(i).x, shape.part(i).y) for i in range(48, 68)])\n",
    "\n",
    "            left_EAR = calculate_EAR(left_eye)\n",
    "            right_EAR = calculate_EAR(right_eye)\n",
    "            avg_EAR = (left_EAR + right_EAR) / 2.0\n",
    "            mar = calculate_MAR(mouth)\n",
    "            height_width_ratio = get_mouth_height_width_ratio(mouth)\n",
    "\n",
    "            is_drowsy = avg_EAR < 0.25\n",
    "            drowsy_status = drowsy_frames >= DROWSY_THRESHOLD if is_drowsy else False\n",
    "            drowsy_frames = drowsy_frames + 1 if is_drowsy else max(0, drowsy_frames - 1)\n",
    "\n",
    "            is_yawning = mar > MAR_THRESHOLD and height_width_ratio > HEIGHT_WIDTH_RATIO_THRESHOLD\n",
    "            yawning_status = yawn_frames >= YAWN_THRESHOLD if is_yawning else False\n",
    "            yawn_frames = yawn_frames + 1 if is_yawning else max(0, yawn_frames - 1)\n",
    "\n",
    "            if drowsy_status:\n",
    "                true_positive_drowsy += is_drowsy\n",
    "                false_positive_drowsy += not is_drowsy\n",
    "            else:\n",
    "                false_negative_drowsy += is_drowsy\n",
    "                true_negative_drowsy += not is_drowsy\n",
    "\n",
    "            if yawning_status:\n",
    "                true_positive_yawn += is_yawning\n",
    "                false_positive_yawn += not is_yawning\n",
    "            else:\n",
    "                false_negative_yawn += is_yawning\n",
    "                true_negative_yawn += not is_yawning\n",
    "\n",
    "            cv2.drawContours(frame, [cv2.convexHull(left_eye)], -1, (0, 255, 0), 1)\n",
    "            cv2.drawContours(frame, [cv2.convexHull(right_eye)], -1, (0, 255, 0), 1)\n",
    "            cv2.drawContours(frame, [cv2.convexHull(mouth)], -1, (0, 0, 255) if yawning_status else (255, 255, 255), 1)\n",
    "\n",
    "            text_lines = [\n",
    "                (f\"Drowsy: {'Yes' if drowsy_status else 'No'}\", 0.7, (0, 255, 0) if drowsy_status else (255, 255, 255), 2),\n",
    "                (f\"Yawning: {'Yes' if yawning_status else 'No'}\", 0.7, (0, 0, 255) if yawning_status else (255, 255, 255), 2),\n",
    "                (f\"Left EAR: {left_EAR:.2f}\", 0.7, (255, 255, 255), 2),\n",
    "                (f\"Right EAR: {right_EAR:.2f}\", 0.7, (255, 255, 255), 2),\n",
    "                (f\"MAR: {mar:.2f}\", 0.7, (255, 255, 255), 2)\n",
    "            ]\n",
    "\n",
    "            add_transparent_overlay(frame, text_lines, 10, 10)\n",
    "\n",
    "        cv2.imshow('Drowsiness Detection', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    precision_drowsy = true_positive_drowsy / (true_positive_drowsy + false_positive_drowsy) if (true_positive_drowsy + false_positive_drowsy) > 0 else 0\n",
    "    recall_drowsy = true_positive_drowsy / (true_positive_drowsy + false_negative_drowsy) if (true_positive_drowsy + false_negative_drowsy) > 0 else 0\n",
    "    f1_score_drowsy = (2 * precision_drowsy * recall_drowsy) / (precision_drowsy + recall_drowsy) if (precision_drowsy + recall_drowsy) > 0 else 0\n",
    "\n",
    "    precision_yawn = true_positive_yawn / (true_positive_yawn + false_positive_yawn) if (true_positive_yawn + false_positive_yawn) > 0 else 0\n",
    "    recall_yawn = true_positive_yawn / (true_positive_yawn + false_negative_yawn) if (true_positive_yawn + false_negative_yawn) > 0 else 0\n",
    "    f1_score_yawn = (2 * precision_yawn * recall_yawn) / (precision_yawn + recall_yawn) if (precision_yawn + recall_yawn) > 0 else 0\n",
    "\n",
    "    print(f\"Drowsy Detection - Precision: {precision_drowsy:.2f}, Recall: {recall_drowsy:.2f}, F1 Score: {f1_score_drowsy:.2f}\")\n",
    "    print(f\"Yawning Detection - Precision: {precision_yawn:.2f}, Recall: {recall_yawn:.2f}, F1 Score: {f1_score_yawn:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67df8a75-b6bd-4d3e-94ec-21965b9e7841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 1/185: A1183.png\n",
      "Processed A1183.png.\n",
      "Processing image 2/185: A1184.png\n",
      "Processed A1184.png.\n",
      "Processing image 3/185: A1185.png\n",
      "Processed A1185.png.\n",
      "Processing image 4/185: A1186.png\n",
      "Processed A1186.png.\n",
      "Processing image 5/185: A1187.png\n",
      "Processed A1187.png.\n",
      "Processing image 6/185: A1195.png\n",
      "Processed A1195.png.\n",
      "Processing image 7/185: A1196.png\n",
      "Processed A1196.png.\n",
      "Processing image 8/185: A1197.png\n",
      "Processed A1197.png.\n",
      "Processing image 9/185: A1198.png\n",
      "Processed A1198.png.\n",
      "Processing image 10/185: A1199.png\n",
      "Processed A1199.png.\n",
      "Processing image 11/185: B0271.png\n",
      "Processed B0271.png.\n",
      "Processing image 12/185: B0272.png\n",
      "Processed B0272.png.\n",
      "Processing image 13/185: B0273.png\n",
      "Processed B0273.png.\n",
      "Processing image 14/185: B0274.png\n",
      "Processed B0274.png.\n",
      "Processing image 15/185: B0275.png\n",
      "Processed B0275.png.\n",
      "Processing image 16/185: B0276.png\n",
      "Processed B0276.png.\n",
      "Processing image 17/185: B0277.png\n",
      "Processed B0277.png.\n",
      "Processing image 18/185: B0283.png\n",
      "Processed B0283.png.\n",
      "Processing image 19/185: B0284.png\n",
      "Processed B0284.png.\n",
      "Processing image 20/185: B0285.png\n",
      "Processed B0285.png.\n",
      "Processing image 21/185: B0286.png\n",
      "Processed B0286.png.\n",
      "Processing image 22/185: B0287.png\n",
      "Processed B0287.png.\n",
      "Processing image 23/185: B0290.png\n",
      "Processed B0290.png.\n",
      "Processing image 24/185: B0291.png\n",
      "Processed B0291.png.\n",
      "Processing image 25/185: C0003.png\n",
      "Processed C0003.png.\n",
      "Processing image 26/185: C0004.png\n",
      "Processed C0004.png.\n",
      "Processing image 27/185: C0005.png\n",
      "Processed C0005.png.\n",
      "Processing image 28/185: C0006.png\n",
      "Processed C0006.png.\n",
      "Processing image 29/185: drowsiness.jpg\n",
      "Processed drowsiness.jpg.\n",
      "Processing image 30/185: E0714.png\n",
      "Processed E0714.png.\n",
      "Processing image 31/185: E0715.png\n",
      "No face detected in E0715.png\n",
      "Processing image 32/185: E0716.png\n",
      "No face detected in E0716.png\n",
      "Processing image 33/185: E0717.png\n",
      "No face detected in E0717.png\n",
      "Processing image 34/185: E0719.png\n",
      "No face detected in E0719.png\n",
      "Processing image 35/185: E0727.png\n",
      "No face detected in E0727.png\n",
      "Processing image 36/185: E0728.png\n",
      "No face detected in E0728.png\n",
      "Processing image 37/185: E0729.png\n",
      "Processed E0729.png.\n",
      "Processing image 38/185: E0730.png\n",
      "Processed E0730.png.\n",
      "Processing image 39/185: E0731.png\n",
      "No face detected in E0731.png\n",
      "Processing image 40/185: E0751.png\n",
      "Processed E0751.png.\n",
      "Processing image 41/185: E0752.png\n",
      "No face detected in E0752.png\n",
      "Processing image 42/185: E0763.png\n",
      "No face detected in E0763.png\n",
      "Processing image 43/185: E0764.png\n",
      "No face detected in E0764.png\n",
      "Processing image 44/185: E0776.png\n",
      "No face detected in E0776.png\n",
      "Processing image 45/185: E0777.png\n",
      "No face detected in E0777.png\n",
      "Processing image 46/185: E0788.png\n",
      "Processed E0788.png.\n",
      "Processing image 47/185: E0789.png\n",
      "Processed E0789.png.\n",
      "Processing image 48/185: H0081.png\n",
      "Processed H0081.png.\n",
      "Processing image 49/185: H0082.png\n",
      "Processed H0082.png.\n",
      "Processing image 50/185: H0083.png\n",
      "Processed H0083.png.\n",
      "Processing image 51/185: H0084.png\n",
      "Processed H0084.png.\n",
      "Processing image 52/185: H0085.png\n",
      "Processed H0085.png.\n",
      "Processing image 53/185: H0093.png\n",
      "Processed H0093.png.\n",
      "Processing image 54/185: H0094.png\n",
      "Processed H0094.png.\n",
      "Processing image 55/185: H0095.png\n",
      "Processed H0095.png.\n",
      "Processing image 56/185: H0096.png\n",
      "Processed H0096.png.\n",
      "Processing image 57/185: H0097.png\n",
      "Processed H0097.png.\n",
      "Processing image 58/185: I0115.png\n",
      "Processed I0115.png.\n",
      "Processing image 59/185: I0116.png\n",
      "Processed I0116.png.\n",
      "Processing image 60/185: I0123.png\n",
      "Processed I0123.png.\n",
      "Processing image 61/185: I0124.png\n",
      "Processed I0124.png.\n",
      "Processing image 62/185: I0136.png\n",
      "Processed I0136.png.\n",
      "Processing image 63/185: I0137.png\n",
      "Processed I0137.png.\n",
      "Processing image 64/185: I0138.png\n",
      "Processed I0138.png.\n",
      "Processing image 65/185: I0139.png\n",
      "Processed I0139.png.\n",
      "Processing image 66/185: I0969.png\n",
      "Processed I0969.png.\n",
      "Processing image 67/185: I0970.png\n",
      "Processed I0970.png.\n",
      "Processing image 68/185: I0971.png\n",
      "Processed I0971.png.\n",
      "Processing image 69/185: I0972.png\n",
      "Processed I0972.png.\n",
      "Processing image 70/185: I0982.png\n",
      "Processed I0982.png.\n",
      "Processing image 71/185: I0983.png\n",
      "Processed I0983.png.\n",
      "Processing image 72/185: I0984.png\n",
      "Processed I0984.png.\n",
      "Processing image 73/185: I0985.png\n",
      "Processed I0985.png.\n",
      "Processing image 74/185: J0145.png\n",
      "Processed J0145.png.\n",
      "Processing image 75/185: J0146.png\n",
      "Processed J0146.png.\n",
      "Processing image 76/185: J0147.png\n",
      "Processed J0147.png.\n",
      "Processing image 77/185: J0148.png\n",
      "Processed J0148.png.\n",
      "Processing image 78/185: K0534.png\n",
      "Processed K0534.png.\n",
      "Processing image 79/185: K0535.png\n",
      "Processed K0535.png.\n",
      "Processing image 80/185: K0536.png\n",
      "Processed K0536.png.\n",
      "Processing image 81/185: K0537.png\n",
      "Processed K0537.png.\n",
      "Processing image 82/185: K0538.png\n",
      "Processed K0538.png.\n",
      "Processing image 83/185: K0539.png\n",
      "Processed K0539.png.\n",
      "Processing image 84/185: K0540.png\n",
      "Processed K0540.png.\n",
      "Processing image 85/185: K0541.png\n",
      "Processed K0541.png.\n",
      "Processing image 86/185: K0546.png\n",
      "Processed K0546.png.\n",
      "Processing image 87/185: K0547.png\n",
      "Processed K0547.png.\n",
      "Processing image 88/185: K0548.png\n",
      "Processed K0548.png.\n",
      "Processing image 89/185: K0549.png\n",
      "Processed K0549.png.\n",
      "Processing image 90/185: K0550.png\n",
      "Processed K0550.png.\n",
      "Processing image 91/185: K0551.png\n",
      "Processed K0551.png.\n",
      "Processing image 92/185: K0552.png\n",
      "Processed K0552.png.\n",
      "Processing image 93/185: K0553.png\n",
      "Processed K0553.png.\n",
      "Processing image 94/185: L0390.png\n",
      "Processed L0390.png.\n",
      "Processing image 95/185: L0391.png\n",
      "Processed L0391.png.\n",
      "Processing image 96/185: L0392.png\n",
      "Processed L0392.png.\n",
      "Processing image 97/185: L0393.png\n",
      "Processed L0393.png.\n",
      "Processing image 98/185: L0402.png\n",
      "Processed L0402.png.\n",
      "Processing image 99/185: L0403.png\n",
      "Processed L0403.png.\n",
      "Processing image 100/185: L0404.png\n",
      "Processed L0404.png.\n",
      "Processing image 101/185: L0405.png\n",
      "Processed L0405.png.\n",
      "Processing image 102/185: L0490.png\n",
      "Processed L0490.png.\n",
      "Processing image 103/185: L0491.png\n",
      "Processed L0491.png.\n",
      "Processing image 104/185: L0492.png\n",
      "Processed L0492.png.\n",
      "Processing image 105/185: L0493.png\n",
      "Processed L0493.png.\n",
      "Processing image 106/185: L0494.png\n",
      "Processed L0494.png.\n",
      "Processing image 107/185: L0520.png\n",
      "Processed L0520.png.\n",
      "Processing image 108/185: L0521.png\n",
      "Processed L0521.png.\n",
      "Processing image 109/185: L0522.png\n",
      "Processed L0522.png.\n",
      "Processing image 110/185: L0523.png\n",
      "Processed L0523.png.\n",
      "Processing image 111/185: L0524.png\n",
      "Processed L0524.png.\n",
      "Processing image 112/185: L0537.png\n",
      "Processed L0537.png.\n",
      "Processing image 113/185: L0538.png\n",
      "Processed L0538.png.\n",
      "Processing image 114/185: L0539.png\n",
      "Processed L0539.png.\n",
      "Processing image 115/185: L0540.png\n",
      "Processed L0540.png.\n",
      "Processing image 116/185: L0541.png\n",
      "Processed L0541.png.\n",
      "Processing image 117/185: M0339.png\n",
      "Processed M0339.png.\n",
      "Processing image 118/185: M0340.png\n",
      "Processed M0340.png.\n",
      "Processing image 119/185: M0341.png\n",
      "Processed M0341.png.\n",
      "Processing image 120/185: M0351.png\n",
      "Processed M0351.png.\n",
      "Processing image 121/185: M0352.png\n",
      "Processed M0352.png.\n",
      "Processing image 122/185: M0353.png\n",
      "Processed M0353.png.\n",
      "Processing image 123/185: N1159.png\n",
      "No face detected in N1159.png\n",
      "Processing image 124/185: N1160.png\n",
      "No face detected in N1160.png\n",
      "Processing image 125/185: N1161.png\n",
      "Processed N1161.png.\n",
      "Processing image 126/185: N1162.png\n",
      "No face detected in N1162.png\n",
      "Processing image 127/185: N1163.png\n",
      "No face detected in N1163.png\n",
      "Processing image 128/185: O0001.png\n",
      "Processed O0001.png.\n",
      "Processing image 129/185: O0002.png\n",
      "Processed O0002.png.\n",
      "Processing image 130/185: O0003.png\n",
      "Processed O0003.png.\n",
      "Processing image 131/185: O0004.png\n",
      "Processed O0004.png.\n",
      "Processing image 132/185: O0005.png\n",
      "Processed O0005.png.\n",
      "Processing image 133/185: P0066.png\n",
      "Processed P0066.png.\n",
      "Processing image 134/185: P0067.png\n",
      "Processed P0067.png.\n",
      "Processing image 135/185: P0068.png\n",
      "Processed P0068.png.\n",
      "Processing image 136/185: P0069.png\n",
      "Processed P0069.png.\n",
      "Processing image 137/185: P0070.png\n",
      "Processed P0070.png.\n",
      "Processing image 138/185: P0071.png\n",
      "Processed P0071.png.\n",
      "Processing image 139/185: ZA0731.png\n",
      "Processed ZA0731.png.\n",
      "Processing image 140/185: ZA0732.png\n",
      "Processed ZA0732.png.\n",
      "Processing image 141/185: ZA0733.png\n",
      "Processed ZA0733.png.\n",
      "Processing image 142/185: ZA0734.png\n",
      "Processed ZA0734.png.\n",
      "Processing image 143/185: ZA0735.png\n",
      "Processed ZA0735.png.\n",
      "Processing image 144/185: ZA0736.png\n",
      "Processed ZA0736.png.\n",
      "Processing image 145/185: ZA0743.png\n",
      "Processed ZA0743.png.\n",
      "Processing image 146/185: ZA0744.png\n",
      "Processed ZA0744.png.\n",
      "Processing image 147/185: ZA0745.png\n",
      "Processed ZA0745.png.\n",
      "Processing image 148/185: ZA0746.png\n",
      "Processed ZA0746.png.\n",
      "Processing image 149/185: ZA0747.png\n",
      "Processed ZA0747.png.\n",
      "Processing image 150/185: ZA0748.png\n",
      "Processed ZA0748.png.\n",
      "Processing image 151/185: ZC0700.png\n",
      "Processed ZC0700.png.\n",
      "Processing image 152/185: ZC0701.png\n",
      "Processed ZC0701.png.\n",
      "Processing image 153/185: ZC0702.png\n",
      "Processed ZC0702.png.\n",
      "Processing image 154/185: ZC0705.png\n",
      "Processed ZC0705.png.\n",
      "Processing image 155/185: ZC0706.png\n",
      "Processed ZC0706.png.\n",
      "Processing image 156/185: ZC0707.png\n",
      "Processed ZC0707.png.\n",
      "Processing image 157/185: ZC0708.png\n",
      "Processed ZC0708.png.\n",
      "Processing image 158/185: ZC0709.png\n",
      "Processed ZC0709.png.\n",
      "Processing image 159/185: ZC0710.png\n",
      "Processed ZC0710.png.\n",
      "Processing image 160/185: ZC0711.png\n",
      "Processed ZC0711.png.\n",
      "Processing image 161/185: ZC0712.png\n",
      "Processed ZC0712.png.\n",
      "Processing image 162/185: ZC0713.png\n",
      "Processed ZC0713.png.\n",
      "Processing image 163/185: ZC0714.png\n",
      "Processed ZC0714.png.\n",
      "Processing image 164/185: ZC0717.png\n",
      "Processed ZC0717.png.\n",
      "Processing image 165/185: ZC0718.png\n",
      "Processed ZC0718.png.\n",
      "Processing image 166/185: ZC0719.png\n",
      "Processed ZC0719.png.\n",
      "Processing image 167/185: ZC0748.png\n",
      "Processed ZC0748.png.\n",
      "Processing image 168/185: ZC0749.png\n",
      "Processed ZC0749.png.\n",
      "Processing image 169/185: ZC0763.png\n",
      "Processed ZC0763.png.\n",
      "Processing image 170/185: ZC0764.png\n",
      "Processed ZC0764.png.\n",
      "Processing image 171/185: ZC0765.png\n",
      "Processed ZC0765.png.\n",
      "Processing image 172/185: ZC0766.png\n",
      "Processed ZC0766.png.\n",
      "Processing image 173/185: ZC0770.png\n",
      "Processed ZC0770.png.\n",
      "Processing image 174/185: zc1269.png\n",
      "Processed zc1269.png.\n",
      "Processing image 175/185: zc1270.png\n",
      "Processed zc1270.png.\n",
      "Processing image 176/185: zc1273.png\n",
      "Processed zc1273.png.\n",
      "Processing image 177/185: zc1274.png\n",
      "Processed zc1274.png.\n",
      "Processing image 178/185: zc1275.png\n",
      "Processed zc1275.png.\n",
      "Processing image 179/185: zc1276.png\n",
      "Processed zc1276.png.\n",
      "Processing image 180/185: zc1277.png\n",
      "Processed zc1277.png.\n",
      "Processing image 181/185: zc1280.png\n",
      "Processed zc1280.png.\n",
      "Processing image 182/185: zc1281.png\n",
      "Processed zc1281.png.\n",
      "Processing image 183/185: zc1282.png\n",
      "Processed zc1282.png.\n",
      "Processing image 184/185: zc1283.png\n",
      "Processed zc1283.png.\n",
      "Processing image 185/185: zc1284.png\n",
      "Processed zc1284.png.\n",
      "Drowsy Detection - Precision: 1.00, Recall: 0.66, F1 Score: 0.80\n",
      "Yawning Detection - Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n"
     ]
    }
   ],
   "source": [
    "#Importing  the dataset from the file of our laptop and find  the drwosiness from the dataset which is already stored in the laptop storage and creating a \n",
    "#new sep folder for storing the processed images of the dataset\n",
    "# Importing the necessary libraries\n",
    "\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "import os\n",
    "\n",
    "def calculate_EAR(eye):\n",
    "    \"\"\"Calculate Eye Aspect Ratio\"\"\"\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    EAR = (A + B) / (2.0 * C)\n",
    "    return EAR\n",
    "\n",
    "def calculate_percentage_eye_closure(eye):\n",
    "    \"\"\"Calculate percentage of eye closure\"\"\"\n",
    "    vertical_distance = dist.euclidean(eye[1], eye[5]) + dist.euclidean(eye[2], eye[4])\n",
    "    horizontal_distance = dist.euclidean(eye[0], eye[3])\n",
    "    return (vertical_distance / (2.0 * horizontal_distance)) * 100\n",
    "\n",
    "def calculate_yawn_distance(mouth):\n",
    "    \"\"\"Calculate vertical distance between lips\"\"\"\n",
    "    if len(mouth) >= 58:\n",
    "        upper_lip = mouth[51]\n",
    "        lower_lip = mouth[57]\n",
    "        return dist.euclidean(upper_lip, lower_lip)\n",
    "    return 0\n",
    "\n",
    "def preprocess_image(frame):\n",
    "    \"\"\"Enhanced preprocessing pipeline for reliable face detection\"\"\"\n",
    "    if frame is None:\n",
    "        return None\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    gray = cv2.fastNlMeansDenoising(gray, None, 10, 7, 21)\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "    gray = cv2.filter2D(gray, -1, kernel)\n",
    "    gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    gray = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    return gray\n",
    "\n",
    "def detect_face_at_scales(detector, frame):\n",
    "    \"\"\"Detect faces at different scales by resizing image\"\"\"\n",
    "    scales = [1.0, 2.0, 0.5]\n",
    "    for scale in scales:\n",
    "        if scale == 1.0:\n",
    "            rects = detector(frame, 0)\n",
    "            if len(rects) > 0:\n",
    "                return rects\n",
    "        else:\n",
    "            resized_frame = cv2.resize(frame, (int(frame.shape[1] * scale), int(frame.shape[0] * scale)))\n",
    "            rects = detector(resized_frame, 0)\n",
    "            if len(rects) > 0:\n",
    "                return dlib.rectangles(\n",
    "                    [dlib.rectangle(int(r.left() / scale), int(r.top() / scale), int(r.right() / scale), int(r.bottom() / scale)) for r in rects]\n",
    "                )\n",
    "    return dlib.rectangles() \n",
    "\n",
    "def add_transparent_overlay(image, text_lines, start_x, start_y, padding=10):\n",
    "    \"\"\"Add a semi-transparent overlay with text\"\"\"\n",
    "    overlay = image.copy()\n",
    "    max_width = max(cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)[0][0] for text, font_scale, _, thickness in text_lines)\n",
    "    total_height = sum(cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)[0][1] + 10 for text, font_scale, _, thickness in text_lines)\n",
    "    \n",
    "    cv2.rectangle(overlay, (start_x - padding, start_y - padding), (start_x + max_width + padding, start_y + total_height + padding), (0, 0, 0), -1)\n",
    "    cv2.addWeighted(overlay, 0.5, image, 0.5, 0, image)\n",
    "    \n",
    "    y = start_y\n",
    "    for text, font_scale, color, thickness in text_lines:\n",
    "        cv2.putText(image, text, (start_x, y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, thickness)\n",
    "        y += cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)[0][1] + 10\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        detector = dlib.get_frontal_face_detector()\n",
    "        predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return\n",
    "\n",
    "    dataset_path = r\"C:\\Users\\nandh\\Downloads\\Driver Drowsiness Dataset (DDD)\\sample\"\n",
    "    output_path = r\"C:\\Users\\nandh\\Downloads\\Driver Drowsiness Dataset (DDD)\\output\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    true_positive_drowsy = false_positive_drowsy = false_negative_drowsy = 0\n",
    "    true_positive_yawn = false_positive_yawn = false_negative_yawn = 0\n",
    "    total_images = len([f for f in os.listdir(dataset_path) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "\n",
    "    for i, filename in enumerate(os.listdir(dataset_path), 1):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            print(f\"Processing image {i}/{total_images}: {filename}\")\n",
    "            frame = cv2.imread(os.path.join(dataset_path, filename))\n",
    "            processed_frame = preprocess_image(frame)\n",
    "            faces = detect_face_at_scales(detector, processed_frame)\n",
    "\n",
    "            if len(faces) == 0:\n",
    "                print(f\"No face detected in {filename}\")\n",
    "                continue\n",
    "\n",
    "            for rect in faces:\n",
    "                shape = predictor(processed_frame, rect)\n",
    "                left_eye = np.array([(shape.part(i).x, shape.part(i).y) for i in range(36, 42)])\n",
    "                right_eye = np.array([(shape.part(i).x, shape.part(i).y) for i in range(42, 48)])\n",
    "                mouth = np.array([(shape.part(i).x, shape.part(i).y) for i in range(48, 68)])\n",
    "\n",
    "                left_EAR = calculate_EAR(left_eye)\n",
    "                right_EAR = calculate_EAR(right_eye)\n",
    "                avg_EAR = (left_EAR + right_EAR) / 2.0\n",
    "                \n",
    "                left_eye_closure = calculate_percentage_eye_closure(left_eye)\n",
    "                right_eye_closure = calculate_percentage_eye_closure(right_eye)\n",
    "                yawn_distance = calculate_yawn_distance(mouth)\n",
    "\n",
    "                # Detection Status\n",
    "                status = \"Drowsy!\" if avg_EAR < 0.25 else \"Not drowsy\"\n",
    "                yawning_status = \"Yawning!\" if yawn_distance > 20 else \"Not Yawning\"\n",
    "\n",
    "                if status == \"Drowsy!\":\n",
    "                    true_positive_drowsy += 1\n",
    "                else:\n",
    "                    false_negative_drowsy += 1\n",
    "\n",
    "                if yawning_status == \"Yawning!\":\n",
    "                    true_positive_yawn += 1\n",
    "                else:\n",
    "                    false_negative_yawn += 1\n",
    "\n",
    "                text_lines = [\n",
    "                    (f\"Status: {status}\", 0.7, (0, 0, 255) if status == \"Drowsy!\" else (0, 255, 0), 2),\n",
    "                    (f\"EAR: {avg_EAR:.2f}\", 0.7, (255, 255, 255), 2),\n",
    "                    (f\"Left Eye: {left_eye_closure:.1f}%\", 0.7, (255, 255, 255), 1),\n",
    "                    (f\"Right Eye: {right_eye_closure:.1f}%\", 0.7, (255, 255, 255), 1),\n",
    "                    (f\"Yawning Status: {yawning_status}\", 0.7, (0, 255, 255), 1)\n",
    "                ]\n",
    "                add_transparent_overlay(frame, text_lines, 10, 10)\n",
    "\n",
    "            cv2.imwrite(os.path.join(output_path, filename), frame)\n",
    "            print(f\"Processed {filename}.\")\n",
    "\n",
    "    # Metrics Calculation\n",
    "    precision_drowsy = true_positive_drowsy / (true_positive_drowsy + false_positive_drowsy) if (true_positive_drowsy + false_positive_drowsy) > 0 else 0\n",
    "    recall_drowsy = true_positive_drowsy / (true_positive_drowsy + false_negative_drowsy) if (true_positive_drowsy + false_negative_drowsy) > 0 else 0\n",
    "    f1_score_drowsy = (2 * precision_drowsy * recall_drowsy) / (precision_drowsy + recall_drowsy) if (precision_drowsy + recall_drowsy) > 0 else 0\n",
    "\n",
    "    precision_yawn = true_positive_yawn / (true_positive_yawn + false_positive_yawn) if (true_positive_yawn + false_positive_yawn) > 0 else 0\n",
    "    recall_yawn = true_positive_yawn / (true_positive_yawn + false_negative_yawn) if (true_positive_yawn + false_negative_yawn) > 0 else 0\n",
    "    f1_score_yawn = (2 * precision_yawn * recall_yawn) / (precision_yawn + recall_yawn) if (precision_yawn + recall_yawn) > 0 else 0\n",
    "\n",
    "    # Metrics Output\n",
    "    print(f\"Drowsy Detection - Precision: {precision_drowsy:.2f}, Recall: {recall_drowsy:.2f}, F1 Score: {f1_score_drowsy:.2f}\")\n",
    "    print(f\"Yawning Detection - Precision: {precision_yawn:.2f}, Recall: {recall_yawn:.2f}, F1 Score: {f1_score_yawn:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
